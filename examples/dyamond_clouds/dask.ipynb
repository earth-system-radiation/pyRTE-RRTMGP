{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "import netCDF4  # noqa\n",
    "\n",
    "from pyrte_rrtmgp.external_data_helpers import download_dyamond2_data\n",
    "\n",
    "# Download the data\n",
    "downloaded_files = download_dyamond2_data(\n",
    "    datetime(2020, 2, 1, 9),\n",
    "    compute_gas_optics=False,\n",
    "    data_dir=\"GEOS-DYAMOND2-data\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import xarray as xr\n",
    "from dask.distributed import Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = Client(n_workers=7, threads_per_worker=7, memory_limit=\"64GB\")\n",
    "client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = xr.open_mfdataset(\n",
    "    \"GEOS-DYAMOND2-data/*inst_01hr_3d_*.nc4\",\n",
    "    drop_variables=[\n",
    "        \"anchor\",\n",
    "        \"cubed_sphere\",\n",
    "        \"orientation\",\n",
    "        \"contacts\",\n",
    "        \"corner_lats\",\n",
    "        \"corner_lons\",\n",
    "    ],\n",
    ")\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the global dataset\n",
    "atmosphere = data.isel(lev=slice(78, 181)).chunk(\n",
    "    {\"Xdim\": 2880, \"Ydim\": 18, \"nf\": 1, \"lev\": -1}\n",
    ")\n",
    "atmosphere"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "\n",
    "from pyrte_rrtmgp import rrtmgp_cloud_optics\n",
    "from pyrte_rrtmgp.data_types import CloudOpticsFiles\n",
    "\n",
    "_cloud_optics_lw = rrtmgp_cloud_optics.load_cloud_optics(\n",
    "    cloud_optics_file=CloudOpticsFiles.LW_BND\n",
    ")\n",
    "\n",
    "\n",
    "def _process_chunk(ds, cloud_optics_lw):\n",
    "    from pyrte_rrtmgp import rrtmgp_cloud_optics  # noqa\n",
    "    from pyrte_rrtmgp.constants import HELMERT1\n",
    "    from pyrte_rrtmgp.data_types import CloudOpticsFiles  # noqa\n",
    "\n",
    "    ds[\"lwp\"] = (ds[\"DELP\"] * ds[\"QL\"]) * 1000 / HELMERT1\n",
    "    ds[\"iwp\"] = (ds[\"DELP\"] * ds[\"QI\"]) * 1000 / HELMERT1\n",
    "    ds[\"rel\"] = ds[\"RL\"] * 1e6\n",
    "    ds[\"rei\"] = ds[\"RI\"] * 1e6\n",
    "    ds = ds.rename({\"lev\": \"layer\"})\n",
    "\n",
    "    ds = ds[[\"lwp\", \"iwp\", \"rel\", \"rei\"]]\n",
    "\n",
    "    # I think best optimization here would be removing the copy()\n",
    "    # on line 107 of __call__\n",
    "    # and figuring out how to avoid the 5 repeated `unstack` calls...\n",
    "    tau_chunk_ds = cloud_optics_lw.compute_cloud_optics(\n",
    "        ds, problem_type=\"absorption\", add_to_input=False\n",
    "    )\n",
    "\n",
    "    # Aggregate over 'bnd' and 'layer' dimensions\n",
    "    tau_agg_chunk = tau_chunk_ds.sum(dim=[\"bnd\", \"layer\"], skipna=True)\n",
    "\n",
    "    # Since we need to return something, let's return the smallest dataset\n",
    "    # possible and then write multifile output from the process_chunk func\n",
    "    # to avoid data transfers\n",
    "\n",
    "    return tau_agg_chunk\n",
    "\n",
    "\n",
    "process_chunk = partial(_process_chunk, cloud_optics_lw=_cloud_optics_lw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dask_data = xr.full_like(atmosphere[\"DELP\"].isel(lev=0, drop=True), np.nan)\n",
    "\n",
    "template_da = xr.DataArray(\n",
    "    data=dask_data,\n",
    "    dims=dask_data.dims,\n",
    "    coords=dask_data.coords,\n",
    ")\n",
    "\n",
    "template_agg = xr.Dataset(\n",
    "    data_vars={\n",
    "        \"tau\": template_da.copy(),\n",
    "        # \"ssa\": template_da.copy(),\n",
    "        # \"g\": template_da.copy()\n",
    "    }\n",
    ")\n",
    "\n",
    "result = xr.map_blocks(\n",
    "    func=process_chunk, obj=atmosphere, template=template_agg\n",
    ")\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.to_netcdf(\"tau.nc\", compute=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "read_results = xr.open_dataset(\"tau.nc\")\n",
    "read_results.tau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
